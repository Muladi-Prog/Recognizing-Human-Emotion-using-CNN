{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "import numpy as np\r\n",
                "import os\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "\r\n",
                "from sklearn.metrics import confusion_matrix\r\n",
                "from mlxtend.plotting import plot_confusion_matrix\r\n",
                "\r\n",
                "from keras import models\r\n",
                "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\r\n",
                "from keras.optimizers import RMSprop,Adam\r\n",
                "from keras.utils import to_categorical"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "data = pd.read_csv('icml_face_data.csv')\r\n",
                "data.head()"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "   emotion     Usage                                             pixels\n",
                            "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
                            "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
                            "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
                            "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
                            "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>emotion</th>\n",
                            "      <th>Usage</th>\n",
                            "      <th>pixels</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>Training</td>\n",
                            "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>Training</td>\n",
                            "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2</td>\n",
                            "      <td>Training</td>\n",
                            "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>4</td>\n",
                            "      <td>Training</td>\n",
                            "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>6</td>\n",
                            "      <td>Training</td>\n",
                            "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 2
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def prepare_data(data):\r\n",
                "    \"\"\" Prepare data for modeling \r\n",
                "        input: data frame with labels und pixel data\r\n",
                "        output: image and label array \"\"\"\r\n",
                "    \r\n",
                "    image_array = np.zeros(shape=(len(data), 48, 48))\r\n",
                "    image_label = np.array(list(map(int, data['emotion'])))\r\n",
                "    \r\n",
                "    for i, row in enumerate(data.index):\r\n",
                "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\r\n",
                "        image = np.reshape(image, (48, 48))\r\n",
                "        image_array[i] = image\r\n",
                "        \r\n",
                "    return image_array, image_label"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\r\n",
                "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\r\n",
                "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\r\n",
                "train_images = train_images.astype('float32')/255\r\n",
                "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\r\n",
                "val_images = val_images.astype('float32')/255\r\n",
                "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\r\n",
                "test_images = test_images.astype('float32')/255"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "train_labels = to_categorical(train_image_label)\r\n",
                "val_labels = to_categorical(val_image_label)\r\n",
                "test_labels = to_categorical(test_image_label)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "model = models.Sequential()\r\n",
                "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\r\n",
                "model.add(MaxPool2D((2, 2)))\r\n",
                "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
                "model.add(MaxPool2D((2, 2)))\r\n",
                "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
                "model.add(Flatten())\r\n",
                "model.add(Dense(64, activation='relu'))\r\n",
                "model.add(Dense(7, activation='softmax'))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "model.summary()"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Model: \"sequential_1\"\n",
                        "_________________________________________________________________\n",
                        "Layer (type)                 Output Shape              Param #   \n",
                        "=================================================================\n",
                        "conv2d_3 (Conv2D)            (None, 46, 46, 32)        320       \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 32)        0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_4 (Conv2D)            (None, 21, 21, 64)        18496     \n",
                        "_________________________________________________________________\n",
                        "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 64)        0         \n",
                        "_________________________________________________________________\n",
                        "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
                        "_________________________________________________________________\n",
                        "flatten_1 (Flatten)          (None, 4096)              0         \n",
                        "_________________________________________________________________\n",
                        "dense_2 (Dense)              (None, 64)                262208    \n",
                        "_________________________________________________________________\n",
                        "dense_3 (Dense)              (None, 7)                 455       \n",
                        "=================================================================\n",
                        "Total params: 318,407\n",
                        "Trainable params: 318,407\n",
                        "Non-trainable params: 0\n",
                        "_________________________________________________________________\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "history = model.fit(train_images, train_labels,\r\n",
                "                    validation_data=(val_images, val_labels),\r\n",
                "                    \r\n",
                "                    epochs=12,\r\n",
                "                    batch_size=64)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 1/12\n",
                        "449/449 [==============================] - 61s 135ms/step - loss: 1.6879 - accuracy: 0.3269 - val_loss: 1.5511 - val_accuracy: 0.4087\n",
                        "Epoch 2/12\n",
                        "449/449 [==============================] - 57s 126ms/step - loss: 1.4822 - accuracy: 0.4314 - val_loss: 1.4125 - val_accuracy: 0.4625\n",
                        "Epoch 3/12\n",
                        "449/449 [==============================] - 56s 124ms/step - loss: 1.3507 - accuracy: 0.4862 - val_loss: 1.3291 - val_accuracy: 0.4898\n",
                        "Epoch 4/12\n",
                        "449/449 [==============================] - 56s 124ms/step - loss: 1.2709 - accuracy: 0.5197 - val_loss: 1.2643 - val_accuracy: 0.5104\n",
                        "Epoch 5/12\n",
                        "449/449 [==============================] - 58s 128ms/step - loss: 1.2045 - accuracy: 0.5467 - val_loss: 1.2705 - val_accuracy: 0.5085\n",
                        "Epoch 6/12\n",
                        "449/449 [==============================] - 54s 120ms/step - loss: 1.1529 - accuracy: 0.5663 - val_loss: 1.2490 - val_accuracy: 0.5216\n",
                        "Epoch 7/12\n",
                        "449/449 [==============================] - 53s 117ms/step - loss: 1.1072 - accuracy: 0.5841 - val_loss: 1.2168 - val_accuracy: 0.5266\n",
                        "Epoch 8/12\n",
                        "449/449 [==============================] - 52s 116ms/step - loss: 1.0660 - accuracy: 0.6002 - val_loss: 1.2272 - val_accuracy: 0.5333\n",
                        "Epoch 9/12\n",
                        "449/449 [==============================] - 52s 115ms/step - loss: 1.0177 - accuracy: 0.6211 - val_loss: 1.2278 - val_accuracy: 0.5411\n",
                        "Epoch 10/12\n",
                        "449/449 [==============================] - 50s 111ms/step - loss: 0.9719 - accuracy: 0.6395 - val_loss: 1.2363 - val_accuracy: 0.5405\n",
                        "Epoch 11/12\n",
                        "449/449 [==============================] - 50s 112ms/step - loss: 0.9344 - accuracy: 0.6529 - val_loss: 1.2346 - val_accuracy: 0.5417\n",
                        "Epoch 12/12\n",
                        "449/449 [==============================] - 51s 114ms/step - loss: 0.8846 - accuracy: 0.6751 - val_loss: 1.2501 - val_accuracy: 0.5444\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "test_loss, test_acc = model.evaluate(test_images, test_labels)\r\n",
                "print('test caccuracy:', test_acc)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "113/113 [==============================] - 3s 26ms/step - loss: 1.2956 - accuracy: 0.5386\n",
                        "test caccuracy: 0.538590133190155\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.4",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.4 64-bit"
        },
        "interpreter": {
            "hash": "7e7df21fdf00a26e36d4e6310a308abb9513233b4a3ec64213ee6595ee7ec7bb"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}